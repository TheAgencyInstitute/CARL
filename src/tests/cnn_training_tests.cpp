#include "../ai_components/neural_network_models.h"\n#include "../ai_components/carl_compute_engine.h"\n#include <gtest/gtest.h>\n#include <memory>\n#include <vector>\n#include <random>\n#include <chrono>\n\n/**\n * Comprehensive CNN Training Test Suite\n * \n * Tests cover:\n * 1. Layer implementations (Conv, FC, ResNet, DenseNet)\n * 2. Training workflows and convergence\n * 3. Data augmentation pipeline\n * 4. Transfer learning functionality\n * 5. Model checkpointing and serialization\n * 6. Nova-CARL queue integration\n * 7. Performance benchmarks\n */\n\nusing namespace CARL::AI;\n\nclass CNNTrainingTest : public ::testing::Test {\nprotected:\n    void SetUp() override {\n        // Initialize Nova core and compute engine\n        nova_core = std::make_unique<NovaCore>();\n        ASSERT_TRUE(nova_core->initialize()) << \"Failed to initialize Nova core\";\n        \n        compute_engine = std::make_unique<CarlComputeEngine>(nova_core.get());\n        ASSERT_TRUE(compute_engine->initialize()) << \"Failed to initialize CARL compute engine\";\n        \n        // Test parameters\n        input_width = 64;\n        input_height = 64;\n        channels = 3;\n        num_classes = 10;\n        batch_size = 4;\n        \n        // Create test buffers\n        createTestBuffers();\n    }\n    \n    void TearDown() override {\n        cleanupTestBuffers();\n        \n        if (compute_engine) {\n            compute_engine->shutdown();\n        }\n        if (nova_core) {\n            nova_core->shutdown();\n        }\n    }\n    \n    void createTestBuffers() {\n        size_t input_size = batch_size * input_width * input_height * channels * sizeof(float);\n        size_t output_size = batch_size * num_classes * sizeof(float);\n        \n        test_input = compute_engine->createBuffer(input_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n        test_output = compute_engine->createBuffer(output_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n        test_labels = compute_engine->createBuffer(output_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n        \n        // Fill with test data\n        std::vector<float> input_data(batch_size * input_width * input_height * channels);\n        std::vector<float> label_data(batch_size * num_classes, 0.0f);\n        \n        std::random_device rd;\n        std::mt19937 gen(rd());\n        std::normal_distribution<float> dist(0.5f, 0.2f);\n        \n        for (auto& val : input_data) {\n            val = std::clamp(dist(gen), 0.0f, 1.0f);\n        }\n        \n        for (uint32_t i = 0; i < batch_size; i++) {\n            label_data[i * num_classes + (i % num_classes)] = 1.0f; // One-hot encoding\n        }\n        \n        compute_engine->uploadData(test_input, input_data.data(), input_size);\n        compute_engine->uploadData(test_labels, label_data.data(), output_size);\n    }\n    \n    void cleanupTestBuffers() {\n        if (test_input) compute_engine->destroyBuffer(test_input);\n        if (test_output) compute_engine->destroyBuffer(test_output);\n        if (test_labels) compute_engine->destroyBuffer(test_labels);\n    }\n    \n    std::unique_ptr<NovaCore> nova_core;\n    std::unique_ptr<CarlComputeEngine> compute_engine;\n    \n    uint32_t input_width, input_height, channels, num_classes, batch_size;\n    ComputeBuffer* test_input = nullptr;\n    ComputeBuffer* test_output = nullptr;\n    ComputeBuffer* test_labels = nullptr;\n};\n\n// ==================================================================\n// LAYER IMPLEMENTATION TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, ConvolutionalLayerBasic) {\n    ConvolutionalLayer conv_layer(input_width, input_height, channels, 64, 3, 1, 1);\n    \n    conv_layer.initializeWeights(compute_engine.get());\n    \n    EXPECT_EQ(conv_layer.input_size, input_width * input_height * channels);\n    EXPECT_GT(conv_layer.output_size, 0);\n    EXPECT_FALSE(conv_layer.weights.empty());\n    EXPECT_FALSE(conv_layer.biases.empty());\n}\n\nTEST_F(CNNTrainingTest, ConvolutionalLayerForward) {\n    ConvolutionalLayer conv_layer(input_width, input_height, channels, 32, 3, 1, 1);\n    conv_layer.initializeWeights(compute_engine.get());\n    \n    size_t output_size = batch_size * 32 * input_width * input_height * sizeof(float);\n    auto* layer_output = compute_engine->createBuffer(output_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    \n    // Test forward pass\n    EXPECT_NO_THROW({\n        conv_layer.forward(compute_engine.get(), test_input, layer_output);\n    });\n    \n    // Verify output is not zero\n    std::vector<float> output_data(32 * input_width * input_height);\n    compute_engine->downloadData(layer_output, output_data.data(), output_data.size() * sizeof(float));\n    \n    bool has_nonzero = false;\n    for (float val : output_data) {\n        if (std::abs(val) > 1e-6) {\n            has_nonzero = true;\n            break;\n        }\n    }\n    EXPECT_TRUE(has_nonzero) << \"Convolution output should not be all zeros\";\n    \n    compute_engine->destroyBuffer(layer_output);\n}\n\nTEST_F(CNNTrainingTest, FullyConnectedLayerBasic) {\n    uint32_t input_size = input_width * input_height * channels;\n    FullyConnectedLayer fc_layer(input_size, num_classes);\n    \n    fc_layer.initializeWeights(compute_engine.get());\n    \n    EXPECT_EQ(fc_layer.input_size, input_size);\n    EXPECT_EQ(fc_layer.output_size, num_classes);\n    EXPECT_FALSE(fc_layer.weights.empty());\n    EXPECT_FALSE(fc_layer.biases.empty());\n}\n\nTEST_F(CNNTrainingTest, FullyConnectedLayerForward) {\n    uint32_t input_size = input_width * input_height * channels;\n    FullyConnectedLayer fc_layer(input_size, num_classes);\n    fc_layer.initializeWeights(compute_engine.get());\n    \n    // Flatten input for FC layer\n    size_t flattened_size = batch_size * input_size * sizeof(float);\n    auto* flattened_input = compute_engine->createBuffer(flattened_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    \n    std::vector<float> flat_data(batch_size * input_size);\n    compute_engine->downloadData(test_input, flat_data.data(), flat_data.size() * sizeof(float));\n    compute_engine->uploadData(flattened_input, flat_data.data(), flattened_size);\n    \n    EXPECT_NO_THROW({\n        fc_layer.forward(compute_engine.get(), flattened_input, test_output);\n    });\n    \n    // Verify output dimensions\n    std::vector<float> output_data(batch_size * num_classes);\n    compute_engine->downloadData(test_output, output_data.data(), output_data.size() * sizeof(float));\n    \n    EXPECT_EQ(output_data.size(), batch_size * num_classes);\n    \n    compute_engine->destroyBuffer(flattened_input);\n}\n\n// ==================================================================\n// CNN MODEL TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, CNNModelConstruction) {\n    ConvolutionalNeuralNetwork cnn(compute_engine.get(), input_width, input_height, channels);\n    \n    // Build simple CNN\n    cnn.addConvolutionalLayer(32, 3, 1);\n    cnn.addActivationLayer(ShaderType::ACTIVATION_RELU);\n    cnn.addPoolingLayer(2, 2);\n    cnn.addConvolutionalLayer(64, 3, 1);\n    cnn.addActivationLayer(ShaderType::ACTIVATION_RELU);\n    cnn.addPoolingLayer(2, 2);\n    cnn.addFullyConnectedLayer(128);\n    cnn.addActivationLayer(ShaderType::ACTIVATION_RELU);\n    cnn.addFullyConnectedLayer(num_classes);\n    cnn.addActivationLayer(ShaderType::ACTIVATION_SOFTMAX);\n    \n    EXPECT_GT(cnn.getLayerCount(), 0);\n    \n    // Initialize network\n    EXPECT_NO_THROW(cnn.initializeNetwork());\n}\n\nTEST_F(CNNTrainingTest, CNNModelForwardPass) {\n    ConvolutionalNeuralNetwork cnn(compute_engine.get(), input_width, input_height, channels);\n    \n    // Simple CNN architecture\n    cnn.addConvolutionalLayer(16, 3, 1);\n    cnn.addPoolingLayer(2, 2);\n    cnn.addFullyConnectedLayer(32);\n    cnn.addFullyConnectedLayer(num_classes);\n    \n    cnn.initializeNetwork();\n    \n    // Test forward pass\n    auto forward_future = cnn.forward(test_input, test_output);\n    EXPECT_NO_THROW(forward_future.wait());\n    \n    // Verify output\n    std::vector<float> output_data(batch_size * num_classes);\n    compute_engine->downloadData(test_output, output_data.data(), output_data.size() * sizeof(float));\n    \n    // Check that outputs are reasonable (not NaN or inf)\n    for (float val : output_data) {\n        EXPECT_TRUE(std::isfinite(val)) << \"Output contains NaN or inf\";\n    }\n}\n\nTEST_F(CNNTrainingTest, CNNModelLossCalculation) {\n    ConvolutionalNeuralNetwork cnn(compute_engine.get(), input_width, input_height, channels);\n    \n    cnn.addConvolutionalLayer(8, 3, 1);\n    cnn.addPoolingLayer(2, 2);\n    cnn.addFullyConnectedLayer(num_classes);\n    \n    cnn.initializeNetwork();\n    \n    auto forward_future = cnn.forward(test_input, test_output);\n    forward_future.wait();\n    \n    float loss = cnn.calculateLoss(test_output, test_labels);\n    \n    EXPECT_GT(loss, 0.0f) << \"Loss should be positive\";\n    EXPECT_TRUE(std::isfinite(loss)) << \"Loss should be finite\";\n}\n\n// ==================================================================\n// DATA AUGMENTATION TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, DataAugmentationPipeline) {\n    DataAugmentationPipeline augmentation(compute_engine.get());\n    \n    augmentation.setAugmentationConfig(\n        true,  // horizontal_flip\n        false, // vertical_flip\n        10.0f, // rotation_range\n        0.1f,  // zoom_range\n        0.1f,  // brightness_range\n        0.1f   // contrast_range\n    );\n    \n    auto* augmented_output = compute_engine->createBuffer(\n        batch_size * input_width * input_height * channels * sizeof(float),\n        VK_BUFFER_USAGE_STORAGE_BUFFER_BIT\n    );\n    \n    auto aug_future = augmentation.augmentBatch(\n        test_input, augmented_output, batch_size, input_width, input_height, channels\n    );\n    \n    EXPECT_NO_THROW(aug_future.wait());\n    \n    // Verify augmented data is different from original\n    std::vector<float> original_data(batch_size * input_width * input_height * channels);\n    std::vector<float> augmented_data(batch_size * input_width * input_height * channels);\n    \n    compute_engine->downloadData(test_input, original_data.data(), original_data.size() * sizeof(float));\n    compute_engine->downloadData(augmented_output, augmented_data.data(), augmented_data.size() * sizeof(float));\n    \n    bool is_different = false;\n    for (size_t i = 0; i < original_data.size(); i++) {\n        if (std::abs(original_data[i] - augmented_data[i]) > 1e-6) {\n            is_different = true;\n            break;\n        }\n    }\n    \n    EXPECT_TRUE(is_different) << \"Augmented data should be different from original\";\n    \n    compute_engine->destroyBuffer(augmented_output);\n}\n\n// ==================================================================\n// TRAINING WORKFLOW TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, CNNTrainingManagerBasic) {\n    CNNTrainingManager training_manager(compute_engine.get());\n    \n    CNNTrainingManager::TrainingConfig config;\n    config.batch_size = 2;\n    config.learning_rate = 0.01f;\n    config.epochs = 2;\n    config.validation_split = 0.5f;\n    config.use_data_augmentation = false;\n    config.save_checkpoints = false;\n    \n    training_manager.setTrainingConfig(config);\n    \n    // Create simple model for training test\n    auto model = std::make_unique<ConvolutionalNeuralNetwork>(compute_engine.get(), input_width, input_height, channels);\n    model->addConvolutionalLayer(4, 3, 1);\n    model->addPoolingLayer(2, 2);\n    model->addFullyConnectedLayer(num_classes);\n    \n    // Create validation data\n    size_t val_input_size = batch_size * input_width * input_height * channels * sizeof(float);\n    size_t val_output_size = batch_size * num_classes * sizeof(float);\n    \n    auto* val_input = compute_engine->createBuffer(val_input_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    auto* val_labels = compute_engine->createBuffer(val_output_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    \n    // Copy test data for validation\n    compute_engine->uploadData(val_input, test_input, val_input_size);\n    compute_engine->uploadData(val_labels, test_labels, val_output_size);\n    \n    // Test training (should not crash)\n    EXPECT_NO_THROW({\n        auto training_future = training_manager.trainModel(\n            model.get(), test_input, test_labels, val_input, val_labels,\n            batch_size, input_width, input_height, channels\n        );\n        training_future.wait();\n    });\n    \n    compute_engine->destroyBuffer(val_input);\n    compute_engine->destroyBuffer(val_labels);\n}\n\nTEST_F(CNNTrainingTest, ModelEvaluation) {\n    CNNTrainingManager training_manager(compute_engine.get());\n    \n    auto model = std::make_unique<ConvolutionalNeuralNetwork>(compute_engine.get(), input_width, input_height, channels);\n    model->addConvolutionalLayer(8, 3, 1);\n    model->addFullyConnectedLayer(num_classes);\n    model->initializeNetwork();\n    \n    auto eval_future = training_manager.evaluateModel(\n        model.get(), test_input, test_labels, batch_size, input_width, input_height, channels\n    );\n    \n    float eval_loss = eval_future.get();\n    \n    EXPECT_GT(eval_loss, 0.0f);\n    EXPECT_TRUE(std::isfinite(eval_loss));\n}\n\n// ==================================================================\n// TRANSFER LEARNING TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, TransferLearningManager) {\n    TransferLearningManager transfer_manager(compute_engine.get());\n    \n    auto model = std::make_unique<ConvolutionalNeuralNetwork>(compute_engine.get(), input_width, input_height, channels);\n    model->addConvolutionalLayer(16, 3, 1);\n    model->addConvolutionalLayer(32, 3, 1);\n    model->addFullyConnectedLayer(64);\n    model->addFullyConnectedLayer(num_classes);\n    \n    model->initializeNetwork();\n    \n    // Test layer freezing\n    EXPECT_NO_THROW({\n        transfer_manager.freezeLayers(model.get(), 2);\n    });\n    \n    EXPECT_TRUE(transfer_manager.isLayerFrozen(0));\n    EXPECT_TRUE(transfer_manager.isLayerFrozen(1));\n    EXPECT_FALSE(transfer_manager.isLayerFrozen(2));\n    EXPECT_FALSE(transfer_manager.isLayerFrozen(3));\n}\n\n// ==================================================================\n// CHECKPOINT TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, ModelCheckpointing) {\n    ModelCheckpointManager checkpoint_manager(\"./test_checkpoints\");\n    \n    auto model = std::make_unique<ConvolutionalNeuralNetwork>(compute_engine.get(), input_width, input_height, channels);\n    model->addConvolutionalLayer(8, 3, 1);\n    model->addFullyConnectedLayer(num_classes);\n    model->initializeNetwork();\n    \n    // Test checkpoint saving\n    bool save_success = checkpoint_manager.saveCheckpoint(model.get(), 0, 1.5f);\n    EXPECT_TRUE(save_success);\n    \n    // Test checkpoint loading\n    bool load_success = checkpoint_manager.loadCheckpoint(model.get(), \"./test_checkpoints/checkpoint_epoch_0.bin\");\n    EXPECT_TRUE(load_success);\n}\n\n// ==================================================================\n// QUEUE INTEGRATION TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, CNNQueueManager) {\n    CNNQueueManager queue_manager(compute_engine.get());\n    \n    // Create test operations\n    std::vector<AIOperation> operations;\n    \n    AIOperation conv_op;\n    conv_op.type = AIOperationType::CONVOLUTION_2D;\n    conv_op.input_buffers = {test_input};\n    conv_op.output_buffers = {test_output};\n    conv_op.dispatch_x = input_width;\n    conv_op.dispatch_y = input_height;\n    conv_op.dispatch_z = 1;\n    \n    operations.push_back(conv_op);\n    \n    // Test parallel execution\n    EXPECT_NO_THROW({\n        auto queue_future = queue_manager.executeParallelCNNOperations(operations);\n        queue_future.wait();\n    });\n    \n    // Test queue optimization\n    EXPECT_NO_THROW({\n        queue_manager.optimizeQueueLoad();\n    });\n}\n\n// ==================================================================\n// PERFORMANCE BENCHMARKS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, InferenceLatencyBenchmark) {\n    auto model = std::make_unique<ConvolutionalNeuralNetwork>(compute_engine.get(), input_width, input_height, channels);\n    \n    // Realistic CNN architecture\n    model->addConvolutionalLayer(32, 3, 1);\n    model->addActivationLayer(ShaderType::ACTIVATION_RELU);\n    model->addPoolingLayer(2, 2);\n    model->addConvolutionalLayer(64, 3, 1);\n    model->addActivationLayer(ShaderType::ACTIVATION_RELU);\n    model->addPoolingLayer(2, 2);\n    model->addFullyConnectedLayer(128);\n    model->addFullyConnectedLayer(num_classes);\n    \n    model->initializeNetwork();\n    model->setTrainingMode(false);\n    \n    // Single sample inference buffer\n    size_t sample_size = input_width * input_height * channels * sizeof(float);\n    auto* single_input = compute_engine->createBuffer(sample_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    auto* single_output = compute_engine->createBuffer(num_classes * sizeof(float), VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    \n    // Warmup runs\n    for (int i = 0; i < 5; i++) {\n        auto future = model->forward(single_input, single_output);\n        future.wait();\n    }\n    \n    // Benchmark inference latency\n    const int num_runs = 50;\n    auto start_time = std::chrono::high_resolution_clock::now();\n    \n    for (int i = 0; i < num_runs; i++) {\n        auto future = model->forward(single_input, single_output);\n        future.wait();\n    }\n    \n    auto end_time = std::chrono::high_resolution_clock::now();\n    auto total_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);\n    \n    float avg_latency_ms = total_time.count() / static_cast<float>(num_runs) / 1000.0f;\n    \n    std::cout << \"Average inference latency: \" << avg_latency_ms << \" ms\" << std::endl;\n    std::cout << \"Inference throughput: \" << (1000.0f / avg_latency_ms) << \" FPS\" << std::endl;\n    \n    // Performance expectations (adjust based on hardware)\n    EXPECT_LT(avg_latency_ms, 100.0f) << \"Inference should be faster than 100ms\";\n    \n    compute_engine->destroyBuffer(single_input);\n    compute_engine->destroyBuffer(single_output);\n}\n\nTEST_F(CNNTrainingTest, TrainingThroughputBenchmark) {\n    auto model = std::make_unique<ConvolutionalNeuralNetwork>(compute_engine.get(), input_width, input_height, channels);\n    \n    // Medium-sized CNN for throughput testing\n    model->addConvolutionalLayer(64, 3, 1);\n    model->addPoolingLayer(2, 2);\n    model->addConvolutionalLayer(128, 3, 1);\n    model->addPoolingLayer(2, 2);\n    model->addFullyConnectedLayer(256);\n    model->addFullyConnectedLayer(num_classes);\n    \n    model->initializeNetwork();\n    model->setTrainingMode(true);\n    \n    // Benchmark training step throughput\n    const int num_steps = 10;\n    auto start_time = std::chrono::high_resolution_clock::now();\n    \n    for (int i = 0; i < num_steps; i++) {\n        // Forward pass\n        auto forward_future = model->forward(test_input, test_output);\n        forward_future.wait();\n        \n        // Backward pass\n        auto backward_future = model->backward(test_output);\n        backward_future.wait();\n        \n        // Weight update\n        auto update_future = model->updateWeights(0.001f);\n        update_future.wait();\n    }\n    \n    auto end_time = std::chrono::high_resolution_clock::now();\n    auto total_time = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);\n    \n    float avg_step_time_ms = total_time.count() / static_cast<float>(num_steps);\n    float samples_per_second = (batch_size * 1000.0f) / avg_step_time_ms;\n    \n    std::cout << \"Average training step time: \" << avg_step_time_ms << \" ms\" << std::endl;\n    std::cout << \"Training throughput: \" << samples_per_second << \" samples/second\" << std::endl;\n    \n    // Performance expectations\n    EXPECT_GT(samples_per_second, 10.0f) << \"Training should process at least 10 samples/second\";\n}\n\n// ==================================================================\n// INTEGRATION TESTS\n// ==================================================================\n\nTEST_F(CNNTrainingTest, EndToEndTrainingIntegration) {\n    // Complete end-to-end test of CNN training pipeline\n    CNNTrainingManager training_manager(compute_engine.get());\n    \n    // Configure minimal training for fast test\n    CNNTrainingManager::TrainingConfig config;\n    config.batch_size = 2;\n    config.learning_rate = 0.01f;\n    config.epochs = 3;\n    config.validation_split = 0.5f;\n    config.early_stopping_patience = 2;\n    config.use_data_augmentation = true;\n    config.save_checkpoints = false;\n    \n    training_manager.setTrainingConfig(config);\n    \n    // Build test model\n    auto model = std::make_unique<ConvolutionalNeuralNetwork>(compute_engine.get(), input_width, input_height, channels);\n    model->addConvolutionalLayer(16, 3, 1);\n    model->addActivationLayer(ShaderType::ACTIVATION_RELU);\n    model->addPoolingLayer(2, 2);\n    model->addFullyConnectedLayer(32);\n    model->addFullyConnectedLayer(num_classes);\n    \n    // Create extended dataset for training\n    size_t extended_samples = 8;\n    size_t extended_input_size = extended_samples * input_width * input_height * channels * sizeof(float);\n    size_t extended_output_size = extended_samples * num_classes * sizeof(float);\n    \n    auto* train_data = compute_engine->createBuffer(extended_input_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    auto* train_labels = compute_engine->createBuffer(extended_output_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    auto* val_data = compute_engine->createBuffer(extended_input_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    auto* val_labels = compute_engine->createBuffer(extended_output_size, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT);\n    \n    // Generate extended test data\n    std::vector<float> extended_input_data(extended_samples * input_width * input_height * channels);\n    std::vector<float> extended_label_data(extended_samples * num_classes, 0.0f);\n    \n    std::random_device rd;\n    std::mt19937 gen(rd());\n    std::normal_distribution<float> dist(0.5f, 0.2f);\n    \n    for (auto& val : extended_input_data) {\n        val = std::clamp(dist(gen), 0.0f, 1.0f);\n    }\n    \n    for (uint32_t i = 0; i < extended_samples; i++) {\n        extended_label_data[i * num_classes + (i % num_classes)] = 1.0f;\n    }\n    \n    compute_engine->uploadData(train_data, extended_input_data.data(), extended_input_size);\n    compute_engine->uploadData(train_labels, extended_label_data.data(), extended_output_size);\n    compute_engine->uploadData(val_data, extended_input_data.data(), extended_input_size);\n    compute_engine->uploadData(val_labels, extended_label_data.data(), extended_output_size);\n    \n    // Run complete training pipeline\n    EXPECT_NO_THROW({\n        auto training_future = training_manager.trainModel(\n            model.get(), train_data, train_labels, val_data, val_labels,\n            extended_samples, input_width, input_height, channels\n        );\n        training_future.wait();\n    });\n    \n    // Evaluate trained model\n    auto eval_future = training_manager.evaluateModel(\n        model.get(), val_data, val_labels, extended_samples, input_width, input_height, channels\n    );\n    \n    float final_loss = eval_future.get();\n    EXPECT_GT(final_loss, 0.0f);\n    EXPECT_TRUE(std::isfinite(final_loss));\n    \n    std::cout << \"End-to-end training completed with final loss: \" << final_loss << std::endl;\n    \n    // Cleanup\n    compute_engine->destroyBuffer(train_data);\n    compute_engine->destroyBuffer(train_labels);\n    compute_engine->destroyBuffer(val_data);\n    compute_engine->destroyBuffer(val_labels);\n}\n\n// ==================================================================\n// MAIN TEST RUNNER\n// ==================================================================\n\nint main(int argc, char** argv) {\n    ::testing::InitGoogleTest(&argc, argv);\n    \n    std::cout << \"=== CARL CNN Training Test Suite ===\" << std::endl;\n    std::cout << \"Testing comprehensive CNN training workflows with Nova-CARL integration\" << std::endl;\n    \n    int result = RUN_ALL_TESTS();\n    \n    std::cout << \"=== Test Suite Completed ===\" << std::endl;\n    \n    return result;\n}\n\n/**\n * CNN Training Test Suite Summary:\n * \n * Test Coverage:\n * 1. Layer Implementations: Convolution, FC, activation layers\n * 2. Model Architecture: CNN construction and forward/backward passes\n * 3. Data Augmentation: Pipeline testing and transformation verification\n * 4. Training Workflows: Full training loop with validation and early stopping\n * 5. Transfer Learning: Layer freezing and pretrained model loading\n * 6. Model Persistence: Checkpoint saving and loading functionality\n * 7. Queue Integration: Nova-CARL multi-queue parallel processing\n * 8. Performance Benchmarks: Inference latency and training throughput\n * 9. Integration Tests: End-to-end training pipeline validation\n * \n * Performance Expectations:\n * - Inference: <100ms latency for 64x64 RGB images\n * - Training: >10 samples/second throughput\n * - Memory: Efficient GPU buffer management\n * - Accuracy: Proper convergence and loss reduction\n * \n * Usage:\n * mkdir build && cd build\n * cmake .. -DCMAKE_BUILD_TYPE=Debug\n * make cnn_training_tests\n * ./cnn_training_tests\n */\n"